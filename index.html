<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
<head><meta http-equiv="Content-Type" content="text/html; charset=utf-8">
	<meta name="viewport" content="width=800">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
    <style type="text/css">
    /* Color scheme stolen from Sergey Karayev */
    a {
    color: #1772d0;
    text-decoration:none;
    }
    a:focus, a:hover {
    color: #f09228;
    text-decoration:none;
    }
    body,td,th,tr,p,a {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px
    }
    .hp-photo{ width:240px; height:240px; border-radius:240px; -webkit-border-radius:240px; -moz-border-radius:240px; }
    strong {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px;
    }
    heading {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 24px;
    }
    papertitle {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 15px;
    font-weight: 700
    }
    name {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 32px;
    }
    .one
    {
    width: 160px;
    height: 160px;
    position: relative;
    }
    .two
    {
    width: 160px;
    height: 160px;
    position: absolute;
    transition: opacity .2s ease-in-out;
    -moz-transition: opacity .2s ease-in-out;
    -webkit-transition: opacity .2s ease-in-out;
    }
    .fade {
     transition: opacity .2s ease-in-out;
     -moz-transition: opacity .2s ease-in-out;
     -webkit-transition: opacity .2s ease-in-out;
    }
    span.highlight {
        background-color: #ffffd0;
    }
    </style>

    <title>Xin Kong</title>
    <!--<link rel="stylesheet" type="text/css" href="/imgs/css" >-->
    <link rel="icon" type="image/png" href="./images/zju.png">
</head>

<body>
<table width="800" border="0" align="center" cellspacing="0" cellpadding="0">
<tbody>
<tr>
<td>


    <!--SECTION 1 -->
    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tbody><tr>
              <td width="68%" valign="middle">
                <p align="center"><name>Xin Kong (孔 昕)</name></p>
                <p align="justify">I am a Master student (Sep. 2018 - ) in the <a href="http://www.cse.zju.edu.cn/english/">College of Control Science and Engineering</a>
                    at <a href="http://www.zju.edu.cn/english/">Zhejiang University</a>,
                    supervised by <a href="https://scholar.google.com/citations?hl=en&user=qYcgBbEAAAAJ&view_op=list_works&sortby=pubdate"> Prof. Yong Liu</a>.
                    Prior to ZJU, I obtained a B.Eng from <a href="http://en.hit.edu.cn/">Harbin Institute Of Technology</a>.

                    </br></br>
                    I'm currently a research intern (Jun. 2020 - ) at Youtu Lab of <a href="https://www.tencent.com/en-us/">Tencent</a> (Shenzhen, China).
                    In my undergraduate study, I was an team member of vision group in <a href="https://baike.baidu.com/item/哈尔滨工业大学竞技机器人队">
                        Harbin Institute of Technology Competition Robotics Team (HITCRT)</a>, named I Hiter (Harbin, China).

                    </br></br>
                    <font color="red">Looking for a 2021 Fall PhD position in computer vision / robotics perception! Welcome to contact me! </font>

	            </br>
                </p><p align="center">
                    <a href="mailto:xinkong[-at-]zju.edu.cn">Email</a> /
                    <!-- <a href="https://scholar.google.com/citations?hl=en&user=VqUAqz8AAAAJ&view_op=list_works&sortby=pubdate">Google Scholar</a> &nbsp;/&nbsp;
                    -->
                    <a href="https://github.com/kxhit"> Github </a>
                </p>
              </td>
			  <td align="right"> <img class="hp-photo" src="./images/kx.jpg" style="width: 240;"></td></tr>
            </tbody>
          </table>

    <!--SECTION 2 -->
    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
       <tbody><tr>
          <td>
          <heading>Research</heading>
           <p align="justify">I'm interested in computer vision and robotics. Currently I'm working on 3D scene understanding, which
               includes 3D semantic segmentation of large-scale point clouds, graph representation learning, 3D tracking and 3D compression.
               I'm also interested in integrating deep learning with SLAM，including but not limited to long-term place recognition, semantically visual localization.
               My research goal is to build intelligent robots that can perceive the real world as humans do, which is hard but worthwhile.
		   <!--</br></br>-->
		   <!--<span class="highlight"><strong>Internship Position: </strong> If you're interested in ...</span> -->
		   </p>
		   </td></tr>
       </tbody>
    </table>


    <!--SECTION 4 -->
    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tbody><tr>
          <td><heading>Publications</heading>
          </td>
          </tr></tbody>
    </table>

    <!--SECTION 5 -->
    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
		<tbody><tr>

        <td width="20%"><img src="./images/IV20/demo.bmp" alt="PontTuset" width="250" style="border-style: none"></td>
            <td width="80%" valign="top">
<!--                todo paper url-->
	            <p><a href="https://2020.ieee-iv.org/">
	            <papertitle>Learning to Compensate the Drift and Error of Gyroscope for Vehicle Localization</papertitle></a>
                <br>Xiangrui Zhao, Chunfang Deng, <strong>Xin Kong</strong>, Yong Liu.
                <br>
                <em>IEEE Intelligent Vehicles Symposium (IV)</em>, 2020. Las Vegas, USA.
                <br>
<!--                <a href="https://arxiv.org/abs/1909.01643">arXiv</a> /-->
                <a href="./images/IV20/demo.mp4">video</a>
                </p><p></p>
			    <p align="justify" style="font-size:13px">We propose a learning based approach to compensate the drift of gyroscope for vehicle localization.</p>
            </td>
        </tr>

        </tbody>
    </table>

    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
		<tbody><tr>

        <td width="20%"><img src="./images/IROS19/pass3d.png" alt="PontTuset" width="250" style="border-style: none"></td>
            <td width="80%" valign="top">
	            <p><a href="https://arxiv.org/abs/1909.01643">
	            <papertitle>PASS3D: Precise and Accelerated Semantic Segmentation for 3D Point Cloud</papertitle></a>
                <br><strong>Xin Kong</strong>, Guangyao Zhai, Baoquan Zhong, Yong Liu.
                <br>
                <em>IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</em>, 2019. Macau, China.
                <br>
                <a href="https://arxiv.org/abs/1909.01643">arXiv</a> /
                <a href="https://www.youtube.com/watch?v=cukEqDuP_Qw">video</a>
                </p><p></p>
			    <p align="justify" style="font-size:13px">We propose a framework to achieve point-wise semantic segmentation for 3D LiDAR point clouds. </p>
            </td>
        </tr>

        </tbody>
    </table>


    <!--SECTION 6 -->
    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tbody><tr>
          <td><heading>Competitions</heading>
          </td>
          </tr></tbody>
    </table>
    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
		<tbody><tr>

            <td width="20%"><img src="./images/BDCI18/bdci.png" alt="PontTuset" width="250" style="border-style: none"></td>
            <td width="80%" valign="top">
	            <p><a href="https://www.datafountain.cn/competitions/314/ranking?isRedance=0&sch=1368&stage=A">
	            <papertitle>自动驾驶三维点云分割 (3D Semantic Segmentation of Point Clouds in autonomous driving scene)</papertitle></a>
                <br>Team: 试一下PointNet. <strong>Xin Kong</strong>, Chang Zhou, Baoquan Zhong.
                <br>
                <em>CCF大数据与计算智能大赛 (CCF Big Data & Computing Intelligence Contest) (BDCI)</em>, 2018. Hangzhou, China.
                <br>Ranking: <strong>9th</strong>/1408 /
                <a href="./images/BDCI18/BDCI-certificate.bmp">Certificate</a> /
                <a href="https://github.com/kxhit/BDCI2018-pointnet-">Code</a>
<!--                    todo open code to public-->
                </p><p></p>
			    <p align="justify" style="font-size:13px">We split a 3D scene into multi grids by sliding 3D bbox and
                    use PointNet++ as backbone to semantically segment 3D point clouds.</p>
            </td>
        </tr>

        <tbody><tr>
            <td width="20%"><img src="./images/ICRA18/robots.jpg" alt="PontTuset" width="250" style="border-style: none"></td>
            <td width="80%" valign="top">
	            <p><a href="https://www.robomaster.com/en-US/resource/pages/announcement/728">
	            <papertitle>ICRA 2018 DJI RoboMaster AI Challenge</papertitle></a>
                <br><a href="./images/ICRA18/team.jpg">Team: I Hiter</a>. Xingguang Zhong, <strong>Xin Kong</strong>, Xiaoyang Lv, Le Qi, Hao Huang, Linrui Tian, Songwei Li
                <br>
                <em> IEEE International Conference on Robotics and Automation (ICRA)</em>, 2018. Brisbane, Australia.
                <br>
                <a href="./images/ICRA18/champion.jpg"><strong>Global Champion</strong> </a> /
                <a href="./images/ICRA18/ranking.jpg">Ranking: <strong>1st</strong>/21 </a>/
                <a href="./images/ICRA18/certificate.bmp">Certificate</a> /
                <a href="/images/ICRA18/ICRA18-DJI.mp4">Video</a> /
                <a href="./images/ICRA18/rules.pdf">Rules</a>
                </p><p></p>
			    <p align="justify" style="font-size:13px">Our team built two fully automatic robots, including <a href="./images/ICRA18/IHiter-tech.pdf">
                    machinery, circuit, control and algorithm</a>. I was responsible for visual servo, localization, navigation and decision-making of robots.</p>
            </td>
        </tr>

        <tbody><tr>
            <td width="20%"><img src="./images/RM17/autofightback.gif" alt="PontTuset" width="250" style="border-style: none"></td>
            <td width="80%" valign="top">
	            <p><a href="https://www.robomaster.com/en-US/robo/history">
	            <papertitle>2017 & 2018 RoboMaster Robotics Competition</papertitle></a>
                <br><a href="./images/RM17/team.jpg">Team: I Hiter</a>. Wei Chen, Yufei Liu, <strong>Xin Kong</strong>, etc. (20+ in total)
                <br>
                <em>China University Robot Competition (全国大学生机器人大赛)</em>, 2017 & 2018. Shenzhen, China.
                <br>
                <a href="./images/RM17/first-prize.bmp"><strong>First Prize</strong> </a> /
                <a href="https://en.wikipedia.org/wiki/RoboMaster#Winners">Ranking: <strong>4th</strong>/200+ </a>/
                <a href="./images/RM17/kx.bmp">Certificate</a> /
                <a href="https://www.bilibili.com/video/av27846163/">Highlights</a>
                </p><p></p>
			    <p align="justify" style="font-size:13px">Our team built more than <a href="https://www.bilibili.com/video/av23489177/">10 complex automatic or semi-automatic robots</a>.
                    I was responsible for <a href="./images/RM17/visual-servo.mp4">visual servo</a>, which involves computer vision, RGB-D camera calibration, machine learning,
                    multithreaded programming, ballistic model modeling, etc.</p>
            </td>
        </tr>

        <tbody><tr>
            <td width="20%"><img src="./images/MCM17/certificate.bmp" alt="PontTuset" width="250" style="border-style: none"></td>
            <td width="80%" valign="top">
	            <p><a href="https://www.comap.com/undergraduate/contests/mcm/contests/2017/problems/">
	            <papertitle>2017 The Mathematical Contest in Modeling (MCM)</papertitle></a>
                <br>Shengqi Li, <strong>Xin Kong</strong>, Shuaishuai Liu
                <br>
                <em> The Consortium for Mathematics and Its Applications (COMAP)</em>, 2017. Online.
                <br>
                <a href="./images/MCM17/certificate.bmp"><strong>Meritorious Winner</strong> (Top 10%) </a> /
                <a href="./images/MCM17/59816.pdf">Paper</a> /
                <a href="./images/MCM17/2017_MCM_Problem_A.pdf">Problems</a>
                </p><p></p>
			    <p align="justify" style="font-size:13px">Our team modeled the practical problems (Managing The Zambezi River) proposed by COMAP into mathematical
                    models. Through background research, reasonable assumptions and optimization analysis, a solution to the problem was obtained.</p>
            </td>
        </tr>

        <tbody><tr>
            <td width="20%"><img src="./images/CUMCM16/certificate.jpg" alt="PontTuset" width="250" style="border-style: none"></td>
            <td width="80%" valign="top">
	            <p><a href="http://en.mcm.edu.cn/html_en/node/03e3d5f626fa97f88c1695efebaa7156.html">
	            <papertitle>2016 The Contemporary Undergraduate Mathematical Contest in Modeling (CUMCM)</papertitle></a>
                <br>Shengqi Li, <strong>Xin Kong</strong>, Shuaishuai Liu
                <br>
                <em>China Society for Industrial and Applied Mathematics (CSIAM)</em>, 2016. Online.
                <br>
                <a href="./images/CUMCM16/certificate.jpg"><strong>National Second Prize</strong> </a> /
                <a href="./images/CUMCM16/A201608007022.pdf">Paper</a> /
                <a href="./images/CUMCM16/CUMCM2016-problem-A-Chinese-version.doc">Problems</a>
                </p><p></p>
			    <p align="justify" style="font-size:13px">Our team modeled the practical problems (Mooring System Design) proposed by CSIAM into mathematical
                    models. Through background research, reasonable assumptions and optimization analysis, a solution to the problem was obtained.</p>
            </td>
        </tr>

        <tbody><tr>
            <td width="20%"><img src="./images/RC16/demo.gif" alt="PontTuset" width="250" style="border-style: none"></td>
            <td width="80%" valign="top">
	            <p><a href="https://en.wikipedia.org/wiki/ABU_Robocon#ABU_Robocon_2016">
	            <papertitle>2016 The ABU Asia-Pacific Robot Contest (ABU Robocon)</papertitle></a>
                <br>Team: HITCRT. Jingyang Wu, Kuang Xu, <strong>Xin Kong</strong>, etc.
                <br>
                <em>Asia-Pacific Broadcasting Union</em>, 2016. Zoucheng, China.
                <br>
                <a href="./images/RC16/first-prize.jpg"><strong>National First Prize</strong> </a> /
                <a href="./images/RC16/certificate.bmp">Certificate</a>
                </p><p></p>
			    <p align="justify" style="font-size:13px">I was a echelon member of the vision group to help the official team members with Ubuntu
                    environment building, camera calibration, and computer vision algorithm testing. Thanks to my seniors for their careful guidance!</p>
            </td>
        </tr>

        </tbody>
    </table>

    <!--SECTION 7 -->
    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tbody><tr>
          <td><heading>Projects</heading>
          </td>
          </tr></tbody>
    </table>

    <!--SECTION 7 -->
    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
<!--todo Quadruped robot perception project-->
        <tbody><tr>
            <td width="20%"><img src="./images/kinect16/demo-rot.gif" alt="PontTuset" width="250" style="border-style: none"></td>
            <td width="80%" valign="top">
                <papertitle>Automatic Dustbin Robot based on Kinect v2</papertitle></a>
                <br>Team: HITCRT. Xingguang Zhong, <strong>Xin Kong</strong>, Chen Yao, etc.
                <br>
                <em>National Innovation Training Program</em>, 2016. Harbin, China.
                <br>
                Bronze Prize of <a href="http://www.tiaozhanbei.net/d1340/newstag/127/">University Zuguang Cup</a>
                </p><p></p>
			    <p align="justify" style="font-size:13px">Our team designed an automatic dustin robot that can catch objects. I was in charge
                    of Kinect development, RGB-D camera calibration, moving object tracking, and trajectory prediction.</p>
            </td>
        </tr>

        <tbody><tr>
            <td width="20%"><img src="./images/patent15/patent.jpg" alt="PontTuset" width="250" style="border-style: none"></td>
            <td width="80%" valign="top">
	            <p><a href="http://pss-system.cnipa.gov.cn/sipopublicsearch/inportal/i18n.shtml?params=902F004CA61084A284089435EAAEA94F59CC921A916ADCEB">
	            <papertitle>Book Sterilizer based on Automatic Page Turning Device </papertitle></a>
                <br><strong>Xin Kong</strong>, Dai Gao, Yiqiu Ding, Jiaming Cui, Jingda Du
                <br>
                <em>College Training Program</em>, 2015. Harbin, China.
                <br>
                <a href="./images/patent15/patent.bmp"><strong>National Invention Patent</strong> </a> /
                <a href="./images/patent15/certificate.jpg">University-level First Prize</a>
                </p><p></p>
			    <p align="justify" style="font-size:13px">Our team designed and implemented an automatic book sterilizer to protect books
                    by cleaning up the bacteria and dust in books. Patent No. ZL 2015103334672.</p>
            </td>
        </tr>

        </tbody>
    </table>


    <!--SECTION 7 -->

    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
       <tbody><tr>
           <td>
           <heading>Honors</heading>
              <p> Nov. 2018, Academic Scholarship - Zhejiang University.</p>
              <p> May. 2018, Outstanding Graduate - Harbin Institute of Technology.</p>
              <p> May. 2018, 3rd Prize of Innovation Scholarship - Ministry of Industry and Information Technology.</p>
              <p> Nov. 2016, 8841 Impact Scholarship - Harbin Institute of Technology.</p>
           </td>
       </tr></tbody>

    </table>

    <!--SECTION 8 -->
    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
       <tbody><tr>
          <td>
          <heading>About Me</heading>
              <p> <strong>Skills</strong>: Python / C / C ++ / Matlab, PyTorch / TensorFlow, Linux, ROS, OpenCV, PCL, Boost</p>
              <p> <strong>Languages</strong>: Chinese: Native. English: CET-6: 525, CET-4: 582.</p>
		   </td></tr>
       </tbody>
    </table>



    <!--SECTION 10 -->
    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
         <tbody><tr>
            <td><br>
               <!--<p align="right"><font size="3">Erd&ouml;s = ? </font><br> -->
		       <p align="right"><font size="2"> Last update: 2020.06.13. <a href="http://www.cs.berkeley.edu/~barron/">Thanks.</a></font></p>
            </td>
         </tr>
         </tbody>
     </table>


</td>
</tr>
</tbody>
</table>
</body>
</html>